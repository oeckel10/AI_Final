{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Project Artificial Intelligence <br>Max Paulenz (A12921301), Friedrich Wenisch (A12921323), Jannis Kaliske (A12921305)\n",
    "Traveling Salesman Problem applied to PCB hole drilling<br>\n",
    "TabuSearch - MetaHeuristic\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "from InputData import *\n",
    "from EvaluationLogic import *\n",
    "from OutputData import *\n",
    "from Solver import *\n",
    "from BestStartSolution import *\n",
    "\n",
    "# Function to process each scenario from start index to end index\n",
    "def process_scenario(start, end):\n",
    "    for i in range(start, end):\n",
    "        if i == 0:\n",
    "            continue  # Skip processing for index 0 if needed\n",
    "\n",
    "        start_time = time.time()  # Start timing the process\n",
    "\n",
    "        # Construct the file path for the scenario's input data\n",
    "        path = 'scenario_example_id_' + str(i) + '.json'\n",
    "        seedNumber = 50  # Seed number for generating initial solution\n",
    "        maxTabuListLength = 35  # Maximum length of the tabu list\n",
    "        maxIterations = 500  # Maximum number of iterations for the tabu search\n",
    "\n",
    "        # Load input data from the specified path\n",
    "        data = InputData(path)\n",
    "        # Generate the best start solution using the provided seed number\n",
    "        firstSolution = BestStartSolution(data.matrix, seedNumber).generate_best_start_solution()\n",
    "\n",
    "        # Perform the tabu search to find the optimal solution\n",
    "        Solver(path).tabuSearch(firstSolution, data.matrix, data.coordinates, path, maxTabuListLength, maxIterations)\n",
    "\n",
    "        end_time = time.time()  # End timing after the process\n",
    "        duration = end_time - start_time  # Calculate the duration of the process\n",
    "\n",
    "        # File path for storing solutions\n",
    "        file_path = 'Solutions\\Solution-' + path.replace('.json', '') + '.csv'\n",
    "\n",
    "        # Read existing data from the CSV file\n",
    "        with open(file_path, mode='r', newline='') as file:\n",
    "            reader = csv.reader(file, delimiter=';')\n",
    "            data = list(reader)\n",
    "\n",
    "        # Append the new duration to the data\n",
    "        data.append([str(duration)])\n",
    "\n",
    "        # Write the updated data back to the CSV file\n",
    "        with open(file_path, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=';')\n",
    "            writer.writerows(data)\n",
    "\n",
    "        # Print the duration for each iteration\n",
    "        print(f\"Iteration {i}: Duration {duration:.2f} seconds\")\n",
    "\n",
    "# Create threads for parallel processing of scenarios\n",
    "threads = []\n",
    "for i in range(0, 16):\n",
    "    t = threading.Thread(target=process_scenario, args=(i*16, i*16+1,))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "# Wait for all threads to complete\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def datatraining():\n",
    "    # Define the column names manually to be used in the DataFrame\n",
    "    column_names = ['Id', 'Coordinates', 'Order', 'Distance', 'Time']\n",
    "\n",
    "    # Directory containing the CSV files\n",
    "    directory = 'Solutions'\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.csv'):  # Check if the file is a CSV\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            # Load the CSV file without using any row as header and specifying column names\n",
    "            data = pd.read_csv(file_path, delimiter=';', index_col=None, header=None)\n",
    "            data = data.T  # Transpose the data to switch rows and columns\n",
    "            data.columns = column_names  # Set the column names to the DataFrame\n",
    "\n",
    "            # Construct the output file path by modifying the filename\n",
    "            output_file_path = 'Datatraining/Datatraining_' + filename.split('_')[-1]\n",
    "\n",
    "            # Export the DataFrame to a new CSV file\n",
    "            data.to_csv(output_file_path, index=False)\n",
    "\n",
    "            # Print the filename and the path where it was saved\n",
    "            print(f'Processed {filename} and saved to {output_file_path}')\n",
    "\n",
    "# Call the function to process the data\n",
    "datatraining()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a71a232f5bc4f832c5cb447a3a248a1ce1147aa6bcdff74c762ba6cefd89ffe5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
